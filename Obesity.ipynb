{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier   \n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier \n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "\n",
    "from Classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ef393",
   "metadata": {},
   "source": [
    "# 1. Basic Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1224b",
   "metadata": {},
   "source": [
    "#### (1) Import Data and get basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data=pd.read_csv(\"ObesityData.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62320e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96610a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all variables\n",
    "num_var=['Age','FCVC','NCP','CH2O','FAF','TUE']\n",
    "cat_var=['Gender','family_history_with_overweight','FAVC','CAEC','SMOKE','SCC','CALC','MTRANS']\n",
    "all_var=num_var+cat_var\n",
    "NObeyesdad_labels=[\n",
    "    'Insufficient_Weight',\n",
    "    'Normal_Weight',\n",
    "    'Overweight_Level_I',\n",
    "    'Overweight_Level_II',\n",
    "    'Obesity_Type_I',\n",
    "    'Obesity_Type_II',\n",
    "    'Obesity_Type_III'\n",
    "]\n",
    "NObeyesdad_labels_for_exploration={}\n",
    "for i in range(len(NObeyesdad_labels)):\n",
    "    NObeyesdad_labels_for_exploration[NObeyesdad_labels[i]]=str(i)+'_'+NObeyesdad_labels[i]\n",
    "for i in range(len(data)):\n",
    "    data.loc[i,'NObeyesdad']=NObeyesdad_labels_for_exploration[data.loc[i,'NObeyesdad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf05de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_trees=[]\n",
    "for x in all_var:\n",
    "    single_trees.append(Classification(data,x,'NObeyesdad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd7185",
   "metadata": {},
   "source": [
    "#### (2) Explore the target 'NObeyesdad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec145b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_order=NObeyesdad_labels_for_exploration.values()\n",
    "single_trees[0].y_diagram(y_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43030ad1",
   "metadata": {},
   "source": [
    "#### (3) Explore each predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in single_trees:\n",
    "    if t.x in num_var:\n",
    "        t.x_diagram()\n",
    "    else:\n",
    "        t.x_diagram(numerical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902a65e",
   "metadata": {},
   "source": [
    "#### (4) Explore relations between each predictor and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in single_trees:\n",
    "    if t.x in num_var:\n",
    "        t.xy_diagram(y_order)\n",
    "    else:\n",
    "        t.xy_diagram(order=y_order,numerical=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12f579",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3578da93",
   "metadata": {},
   "source": [
    "#### (1) Process invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data[all_var+['NObeyesdad']]\n",
    "# Remove invalid values\n",
    "data1.replace(to_replace=r'^\\s*$',value=np.nan,regex=True,inplace=True)\n",
    "data1.drop_duplicates()\n",
    "data1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54073861",
   "metadata": {},
   "source": [
    "#### (2) Encode categorical predictors to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all categorical variables to numerical\n",
    "oe = OrdinalEncoder()\n",
    "data1[cat_var] = oe.fit_transform(data1[cat_var]) \n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915458e",
   "metadata": {},
   "source": [
    "# 3.Single Decision Tree on Each Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34f7b4",
   "metadata": {},
   "source": [
    "#### (1) Create trees on each predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f62425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through experiments, depth=10 is the best for single decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e51c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_trees=[]\n",
    "for x in all_var:\n",
    "    t=Classification(data1,x,'NObeyesdad')\n",
    "    t.apply_tree(max_depth=6)\n",
    "    single_trees.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e5e51",
   "metadata": {},
   "source": [
    "#### (2) Print goodness of each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80036245",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of each model:\")\n",
    "for t in single_trees:\n",
    "    t.print_goodness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c541b7e7",
   "metadata": {},
   "source": [
    "#### (3) Draw confusion matrices for each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609060a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion_matrices of each model:\")\n",
    "for t in single_trees:\n",
    "    t.draw_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d06533",
   "metadata": {},
   "source": [
    "# 4. Multi-Variate Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b0d60",
   "metadata": {},
   "source": [
    "#### (1) Create the multi-variate decision tree and configure the parameter \"max_depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree=Classification(data1,all_var,'NObeyesdad')\n",
    "best_depth=0\n",
    "best_test_accuracy=0\n",
    "accuracy_list=[0]\n",
    "for d in range(1,21):    \n",
    "    multitree.apply_tree(max_depth=d)\n",
    "    train_accuracy=round(multitree.tree.score(multitree.x_train, multitree.y_train)*100,1)\n",
    "    test_accuracy=round(multitree.tree.score(multitree.x_test, multitree.y_test)*100,1)\n",
    "    accuracy_list.append((train_accuracy,test_accuracy))\n",
    "    if test_accuracy>best_test_accuracy:\n",
    "        best_test_accuracy=test_accuracy\n",
    "        best_depth=d\n",
    "for i in range(1,len(accuracy_list)):\n",
    "    print(f\"Depth: {i}, Accuracy: {accuracy_list[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa7cee",
   "metadata": {},
   "source": [
    "#### (2) Apply the best depth (with highest prediction accuracy on test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff419305",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree.apply_tree(max_depth=best_depth)\n",
    "print(\"Best depth:\",best_depth)\n",
    "multitree.print_goodness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669d5b75",
   "metadata": {},
   "source": [
    "#### (3) Draw the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree.draw_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcaee9f",
   "metadata": {},
   "source": [
    "# 5. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83301cd1",
   "metadata": {},
   "source": [
    "#### (1) Create the random forest and configure the parameter \"max_depth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925718ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree=Classification(data1,all_var,'NObeyesdad')\n",
    "best_depth=0\n",
    "best_test_accuracy=0\n",
    "accuracy_list=[0]\n",
    "for d in range(1,21):    \n",
    "    multitree.apply_RandomForest(n_estimators=50,max_depth=d)\n",
    "    train_accuracy=round(multitree.tree.score(multitree.x_train, multitree.y_train)*100,1)\n",
    "    test_accuracy=round(multitree.tree.score(multitree.x_test, multitree.y_test)*100,1)\n",
    "    accuracy_list.append((train_accuracy,test_accuracy))\n",
    "    if test_accuracy>best_test_accuracy:\n",
    "        best_test_accuracy=test_accuracy\n",
    "        best_depth=d\n",
    "for i in range(1,len(accuracy_list)):\n",
    "    print(f\"Depth: {i}, Accuracy: {accuracy_list[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5036db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'training' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 244, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/apple/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'training' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A child process terminated abruptly, the process pool is not usable anymore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 59\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m                multitree.apply_RandomForest(\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m                    n_estimators=50,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m                    best_leaf=l\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m                '''\u001b[39;00m\n\u001b[1;32m     57\u001b[0m                 inputs\u001b[38;5;241m.\u001b[39mappend([multitree,n,d,s,l,[best_n,best_depth,best_split,best_leaf,best_test_accuracy]])\n\u001b[0;32m---> 59\u001b[0m multi_process(inputs)\n",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m, in \u001b[0;36mmulti_process\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_process\u001b[39m(inputs):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 34\u001b[0m         pool\u001b[38;5;241m.\u001b[39mmap(training,inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/process.py:820\u001b[0m, in \u001b[0;36mProcessPoolExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunksize must be >= 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 820\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mmap(partial(_process_chunk, fn),\n\u001b[1;32m    821\u001b[0m                       _get_chunks(\u001b[38;5;241m*\u001b[39miterables, chunksize\u001b[38;5;241m=\u001b[39mchunksize),\n\u001b[1;32m    822\u001b[0m                       timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chain_from_iterable_of_lists(results)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:608\u001b[0m, in \u001b[0;36mExecutor.map\u001b[0;34m(self, fn, timeout, chunksize, *iterables)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 608\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:608\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;241m+\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 608\u001b[0m fs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(fn, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39miterables)]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# before the first iterator value is required.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult_iterator\u001b[39m():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/process.py:774\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_lock:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken:\n\u001b[0;32m--> 774\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BrokenProcessPool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broken)\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown_thread:\n\u001b[1;32m    776\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A child process terminated abruptly, the process pool is not usable anymore"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "multitree=Classification(data1,all_var,'NObeyesdad')\n",
    "\n",
    "best_n=[0]\n",
    "best_depth=[0]\n",
    "best_split=[0]\n",
    "best_leaf=[0]\n",
    "\n",
    "best_test_accuracy=[0]\n",
    "\n",
    "#args=multitree,n,d,s,l,lists=[best_n,best_depth,best_split,best_leaf,best_test_accuracy]\n",
    "def training(args):\n",
    "    multitree,n,d,s,l,lists=args\n",
    "    best_n,best_depth,best_split,best_leaf,best_test_accuracy=lists\n",
    "\n",
    "    tree_copy=deepcopy(multitree)\n",
    "    tree_copy.apply_RandomForest(\n",
    "        n_estimators=n,\n",
    "        max_depth=d,\n",
    "        min_samples_split=s,\n",
    "        min_samples_leaf=l)\n",
    "    test_accuracy=round(tree_copy.tree.score(multitree.x_test, multitree.y_test)*100,1)\n",
    "    if test_accuracy>best_test_accuracy[0]:\n",
    "        best_n[0]=n\n",
    "        best_depth[0]=d\n",
    "        best_split[0]=s\n",
    "        best_leaf[0]=l\n",
    "        best_test_accuracy[0]=test_accuracy\n",
    "\n",
    "def multi_process(inputs):\n",
    "    with ProcessPoolExecutor() as pool:\n",
    "        pool.map(training,inputs)\n",
    "\n",
    "\n",
    "inputs=[]\n",
    "for n in range(40,60):  \n",
    "    for d in range(1,21):  \n",
    "        for s in range(2,6):\n",
    "            for l in range(1,6):\n",
    "                '''\n",
    "                multitree.apply_RandomForest(\n",
    "                    n_estimators=50,\n",
    "                    max_depth=d,\n",
    "                    min_samples_split=s,\n",
    "                    min_samples_leaf=l)\n",
    "                train_accuracy=round(multitree.tree.score(multitree.x_train, multitree.y_train)*100,1)\n",
    "                test_accuracy=round(multitree.tree.score(multitree.x_test, multitree.y_test)*100,1)\n",
    "                if test_accuracy>best_test_accuracy:\n",
    "                    best_test_accuracy=test_accuracy\n",
    "                    best_n=n\n",
    "                    best_depth=d\n",
    "                    best_split=s\n",
    "                    best_leaf=l\n",
    "                '''\n",
    "                inputs.append([multitree,n,d,s,l,[best_n,best_depth,best_split,best_leaf,best_test_accuracy]])\n",
    "\n",
    "multi_process(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best depth:\",best_depth)\n",
    "multitree.apply_RandomForest(n_estimators=50,max_depth=best_depth)\n",
    "multitree.print_goodness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "n_estimators= [10, 50, 100, 200, 400]\n",
    "max_depth= [None, 10, 20, 30, 50]\n",
    "min_samples_split= [2, 5, 10]\n",
    "min_samples_leaf= [1, 2, 4]\n",
    "max_features=['log2', 'sqrt']\n",
    "\n",
    "max_scores=[0,0]\n",
    "max_combinations=[0,0,0,0,0]\n",
    "for a in n_estimators:\n",
    "    for b in max_depth:\n",
    "        for c in min_samples_split:\n",
    "            for d in min_samples_leaf:\n",
    "                for e in max_features:\n",
    "                    multitree.apply_RandomForest(\n",
    "                        n_estimators=a,\n",
    "                        max_depth=b,\n",
    "                        min_samples_split=c,\n",
    "                        min_samples_leaf=d,\n",
    "                        max_features=e,\n",
    "                    )\n",
    "                    train_score=round(multitree.tree.score(multitree.x_train, multitree.y_train),2)\n",
    "                    test_score=round(multitree.tree.score(multitree.x_test, multitree.y_test),2)\n",
    "                    multitree.print_goodness()\n",
    "                    if test_score>max_scores[1]:\n",
    "                        max_scores=[train_score,test_score]\n",
    "                        max_combinations=[a,b,c,d,e]\n",
    "multitree.apply_RandomForest(\n",
    "    n_estimators=max_combinations[0],\n",
    "    max_depth=max_combinations[1],\n",
    "    min_samples_split=max_combinations[2],\n",
    "    min_samples_leaf=max_combinations[3],\n",
    "    max_features=max_combinations[4],\n",
    ")\n",
    "multitree.print_goodness()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1d3a1",
   "metadata": {},
   "source": [
    "#### (2) Draw the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368802ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree.draw_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af70d738",
   "metadata": {},
   "source": [
    "# 6. More models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed444e",
   "metadata": {},
   "source": [
    "#### (1) These are some other models for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('DecisionTree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=42)),\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df821186",
   "metadata": {},
   "source": [
    "#### (2) Apply each model (very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39744df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree.apply_more_models(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24d06e",
   "metadata": {},
   "source": [
    "#### (3) Print the result of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d66405",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitree.print_more_models_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
